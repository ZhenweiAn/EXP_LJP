Some weights of the model checkpoint at ../../../RESOURCE/chinese_wwm_ext_pytorch were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
start loading
end loading
681
681
133
133
133
133
149
dataset loaded
linear.weight   torch.Size([768, 768])
linear.bias   torch.Size([768])
Classify_layer.weight   torch.Size([4, 768])
Classify_layer.bias   torch.Size([4])
start training
0  loss:  0.9821689128875732
0  loss:  0.29854118824005127
0  loss:  0.15382519364356995
0  loss:  0.08465263247489929
0  loss:  0.13359321653842926
0  loss:  0.13667364418506622
0  loss:  0.10787820816040039
0  loss:  0.13796156644821167
0  loss:  0.15127503871917725
0  loss:  0.04774603247642517
0  loss:  0.06855027377605438
0  loss:  0.20112085342407227
0  loss:  0.12985461950302124
0  loss:  0.1381911039352417
0  loss:  0.21995951235294342
0  loss:  0.11598389595746994
0  loss:  0.10836789757013321
0  loss:  0.10554634034633636
0  loss:  0.1388268917798996
0  loss:  0.09939149767160416
0  loss:  0.09001615643501282
0  loss:  0.18830198049545288
0  loss:  0.09689072519540787
0  loss:  0.11739695072174072
0  loss:  0.05431347340345383
0  loss:  0.07839906960725784
0  loss:  0.10809885710477829
0  loss:  0.07632401585578918
0  loss:  0.09041710197925568
0  loss:  0.09792783856391907
0  loss:  0.10734739899635315
0  loss:  0.13866400718688965
0  loss:  0.05774196237325668
0  loss:  0.07732800394296646
0  loss:  0.15914520621299744
0  loss:  0.22353848814964294
0  loss:  0.19565986096858978
0  loss:  0.15209557116031647
0  loss:  0.11809389293193817
0  loss:  0.15171778202056885
0  loss:  0.14375880360603333
0  loss:  0.1712549775838852
0  loss:  0.09449900686740875
0  loss:  0.16328221559524536
0  loss:  0.05607904493808746
0  loss:  0.1509784311056137
0  loss:  0.1904800832271576
0  loss:  0.03695204481482506
0  loss:  0.23425060510635376
0  loss:  0.13226738572120667
0  loss:  0.06290213763713837
0  loss:  0.16016404330730438
0  loss:  0.08167345076799393
0  loss:  0.11644063144922256
0  loss:  0.05913038179278374
0  loss:  0.15543106198310852
0  loss:  0.1699436604976654
0  loss:  0.22995373606681824
0  loss:  0.12456118315458298
0  loss:  0.16891206800937653
0  loss:  0.24107739329338074
0  loss:  0.1489792764186859
0  loss:  0.1861627995967865
0  loss:  0.12124640494585037
0  loss:  0.181899756193161
0  loss:  0.11824440211057663
0  loss:  0.162869393825531
0  loss:  0.1892668753862381
0  loss:  0.19816969335079193
0  loss:  0.1093699038028717
0  loss:  0.10248631983995438
0  loss:  0.0731189176440239
0  loss:  0.07982226461172104
0  loss:  0.09387139230966568
0  loss:  0.21945276856422424
0  loss:  0.12513244152069092
0  loss:  0.18564516305923462
0  loss:  0.1390886902809143
0  loss:  0.22110435366630554
0  loss:  0.08938086032867432
0  loss:  0.04967333376407623
0  loss:  0.01396584790199995
0  loss:  0.07945690304040909
0  loss:  0.13546326756477356
0  loss:  0.07441362738609314
0  loss:  0.15210159122943878
0  loss:  0.1473754346370697
0  loss:  0.12549898028373718
0  loss:  0.17613159120082855
0  loss:  0.04041237384080887
0  loss:  0.12720312178134918
0  loss:  0.05205008387565613
0  loss:  0.08388570696115494
0  loss:  0.13017809391021729
0  loss:  0.07189592719078064
0  loss:  0.1246732547879219
0  loss:  0.10742820054292679
0  loss:  0.21850532293319702
0  loss:  0.09843733161687851
0  loss:  0.007966750301420689
------ 全部罪名 ------
Acc:  0.7951401869158878
mi_f1:  0.6412443552433518
ma_f1:  0.6399481313468995
mi_precision:  0.7370242214532872
mi_recall:  0.5674955595026643
------ 交通肇事 ------
Acc:  0.9143576826196473
mi_f1:  0.8571428571428572
ma_f1:  0.8645319793793349
mi_precision:  0.8407643312101911
mi_recall:  0.8741721854304636
------ 抢劫 ------
Acc:  0.706989247311828
mi_f1:  0.5484949832775919
ma_f1:  0.5150420064245119
mi_precision:  0.6949152542372882
mi_recall:  0.4530386740331492
------ 抢夺 ------
Acc:  0.7461139896373057
mi_f1:  0.5714285714285713
ma_f1:  0.583160609274077
mi_precision:  0.6330935251798561
mi_recall:  0.5207100591715976
------ 过失致人死亡 ------
Acc:  0.8351063829787234
mi_f1:  0.7018867924528301
ma_f1:  0.7080413464818617
mi_precision:  0.7209302325581395
mi_recall:  0.6838235294117647
------ 贪污 ------
Acc:  0.7828054298642534
mi_f1:  0.49795918367346936
ma_f1:  0.4939435840707965
mi_precision:  0.6421052631578947
mi_recall:  0.4066666666666667
------ 挪用公款 ------
Acc:  0.7478753541076487
mi_f1:  0.5522388059701493
ma_f1:  0.5136386768447837
mi_precision:  0.7254901960784313
mi_recall:  0.4457831325301205
------ 挪用资金 ------
Acc:  0.828080229226361
mi_f1:  0.7266666666666666
ma_f1:  0.7128352128352129
mi_precision:  0.8582677165354331
mi_recall:  0.630057803468208
0   tensor(6.2847, device='cuda:0', grad_fn=<CopyBackwards>)
1   tensor(0., device='cuda:0', grad_fn=<CopyBackwards>)
2   tensor(0., device='cuda:0', grad_fn=<CopyBackwards>)
3   tensor(0., device='cuda:0', grad_fn=<CopyBackwards>)
4   tensor(0., device='cuda:0', grad_fn=<CopyBackwards>)
5   tensor(0., device='cuda:0', grad_fn=<CopyBackwards>)
6   tensor(0., device='cuda:0', grad_fn=<CopyBackwards>)
7   tensor(0., device='cuda:0', grad_fn=<CopyBackwards>)
8   tensor(0., device='cuda:0', grad_fn=<CopyBackwards>)
9   tensor(0., device='cuda:0', grad_fn=<CopyBackwards>)
10   tensor(0., device='cuda:0', grad_fn=<CopyBackwards>)
11   tensor(0., device='cuda:0', grad_fn=<CopyBackwards>)
dataset loaded
linear.weight   torch.Size([768, 768])
linear.bias   torch.Size([768])
Classify_layer.weight   torch.Size([4, 768])
Classify_layer.bias   torch.Size([4])
start training
0  loss:  0.9562627077102661
0  loss:  0.3142607808113098
0  loss:  0.16113877296447754
0  loss:  0.15426874160766602
0  loss:  0.16682186722755432
0  loss:  0.1171608716249466
0  loss:  0.2463921755552292
0  loss:  0.1241942048072815
0  loss:  0.03761986643075943
0  loss:  0.03337240219116211
0  loss:  0.12035369873046875
0  loss:  0.083797886967659
0  loss:  0.12615583837032318
0  loss:  0.1399971842765808
0  loss:  0.20659835636615753
0  loss:  0.19648940861225128
0  loss:  0.09405522048473358
0  loss:  0.23701496422290802
0  loss:  0.09791858494281769
0  loss:  0.1362563818693161
0  loss:  0.08598144352436066
0  loss:  0.13451284170150757
0  loss:  0.14787741005420685
0  loss:  0.13114352524280548
0  loss:  0.1909109354019165
0  loss:  0.17557711899280548
0  loss:  0.1025661826133728
0  loss:  0.19522926211357117
0  loss:  0.14877809584140778
0  loss:  0.1464361548423767
0  loss:  0.18840621411800385
0  loss:  0.1732795536518097
0  loss:  0.1723237782716751
0  loss:  0.06066419184207916
0  loss:  0.2260371893644333
0  loss:  0.21721415221691132
0  loss:  0.12948940694332123
0  loss:  0.17607931792736053
0  loss:  0.16884206235408783
0  loss:  0.0700460821390152
0  loss:  0.1330195516347885
0  loss:  0.04173286631703377
0  loss:  0.2187534123659134
0  loss:  0.17775367200374603
0  loss:  0.099856436252594
0  loss:  0.12890751659870148
0  loss:  0.22726427018642426
0  loss:  0.13339824974536896
0  loss:  0.1390792429447174
0  loss:  0.07075051218271255
0  loss:  0.22980459034442902
0  loss:  0.13744010031223297
0  loss:  0.2112983614206314
0  loss:  0.03326510265469551
0  loss:  0.11147776991128922
0  loss:  0.1995149701833725
0  loss:  0.10792550444602966
0  loss:  0.07665625959634781
0  loss:  0.22824302315711975
0  loss:  0.20939026772975922
0  loss:  0.16010485589504242
0  loss:  0.1276816576719284
0  loss:  0.18892954289913177
0  loss:  0.12887467443943024
0  loss:  0.19879473745822906
0  loss:  0.08036619424819946
0  loss:  0.08276894688606262
0  loss:  0.07165879011154175
0  loss:  0.21633435785770416
0  loss:  0.03840808570384979
0  loss:  0.12965165078639984
0  loss:  0.08338817209005356
0  loss:  0.10333645343780518
0  loss:  0.13165827095508575
0  loss:  0.14460347592830658
0  loss:  0.1276424378156662
0  loss:  0.16661684215068817
0  loss:  0.11041401326656342
0  loss:  0.0623764768242836
0  loss:  0.15976767241954803
0  loss:  0.11082836240530014
0  loss:  0.1830948144197464
0  loss:  0.11966437101364136
0  loss:  0.15269486606121063
0  loss:  0.2778846323490143
0  loss:  0.1765422523021698
0  loss:  0.10689198970794678
0  loss:  0.05708219110965729
0  loss:  0.16364099085330963
0  loss:  0.1673070341348648
0  loss:  0.052510038018226624
0  loss:  0.1395166963338852
0  loss:  0.1225108653306961
0  loss:  0.031754620373249054
0  loss:  0.13159357011318207
0  loss:  0.3083367645740509
0  loss:  0.11236915737390518
0  loss:  0.13783304393291473
0  loss:  0.15682156383991241
0  loss:  0.1182854026556015
------ 全部罪名 ------
Acc:  0.8254185172531602
mi_f1:  0.6446558477895915
ma_f1:  0.6438175365117427
mi_precision:  0.760898282694848
mi_recall:  0.5592233009708738
------ 交通肇事 ------
Acc:  0.9285714285714286
mi_f1:  0.8592592592592593
ma_f1:  0.8587568211308412
mi_precision:  0.8787878787878788
mi_recall:  0.8405797101449275
------ 抢劫 ------
Acc:  0.7624190064794817
mi_f1:  0.5870967741935483
ma_f1:  0.5830277349768874
mi_precision:  0.7109375
mi_recall:  0.5
------ 抢夺 ------
Acc:  0.8463414634146341
mi_f1:  0.6399999999999999
ma_f1:  0.6346700083542189
mi_precision:  0.7912087912087912
mi_recall:  0.5373134328358209
------ 过失致人死亡 ------
Acc:  0.8196286472148541
mi_f1:  0.6666666666666667
ma_f1:  0.6603795136330141
mi_precision:  0.7394957983193278
mi_recall:  0.6068965517241379
------ 贪污 ------
Acc:  0.7974137931034483
mi_f1:  0.46296296296296297
ma_f1:  0.4689573486965422
mi_precision:  0.7692307692307693
mi_recall:  0.33112582781456956
------ 挪用公款 ------
Acc:  0.8011869436201781
mi_f1:  0.6255506607929515
ma_f1:  0.573919328915174
mi_precision:  0.7553191489361702
mi_recall:  0.5338345864661654
------ 挪用资金 ------
Acc:  0.8267543859649122
mi_f1:  0.64
ma_f1:  0.63349848471427
mi_precision:  0.6875
mi_recall:  0.5986394557823129
0   tensor(5.9894, device='cuda:0', grad_fn=<CopyBackwards>)
1   tensor(0., device='cuda:0', grad_fn=<CopyBackwards>)
2   tensor(0., device='cuda:0', grad_fn=<CopyBackwards>)
3   tensor(0., device='cuda:0', grad_fn=<CopyBackwards>)
4   tensor(0., device='cuda:0', grad_fn=<CopyBackwards>)
5   tensor(0., device='cuda:0', grad_fn=<CopyBackwards>)
6   tensor(0., device='cuda:0', grad_fn=<CopyBackwards>)
7   tensor(0., device='cuda:0', grad_fn=<CopyBackwards>)
8   tensor(0., device='cuda:0', grad_fn=<CopyBackwards>)
9   tensor(0., device='cuda:0', grad_fn=<CopyBackwards>)
10   tensor(0., device='cuda:0', grad_fn=<CopyBackwards>)
11   tensor(0., device='cuda:0', grad_fn=<CopyBackwards>)
dataset loaded
linear.weight   torch.Size([768, 768])
linear.bias   torch.Size([768])
Classify_layer.weight   torch.Size([4, 768])
Classify_layer.bias   torch.Size([4])
start training
0  loss:  0.9925665259361267
0  loss:  0.2786683142185211
0  loss:  0.15745680034160614
0  loss:  0.23273633420467377
0  loss:  0.2893533706665039
0  loss:  0.06645960360765457
0  loss:  0.16847144067287445
0  loss:  0.125362828373909
0  loss:  0.10889430344104767
0  loss:  0.12499482184648514
0  loss:  0.10992589592933655
0  loss:  0.15570703148841858
0  loss:  0.1734193116426468
0  loss:  0.11337029188871384
0  loss:  0.14300532639026642
0  loss:  0.33878445625305176
0  loss:  0.23001985251903534
0  loss:  0.18199199438095093
0  loss:  0.0815044492483139
0  loss:  0.1458652764558792
0  loss:  0.22048020362854004
0  loss:  0.02808249555528164
0  loss:  0.10642576962709427
0  loss:  0.1836341768503189
0  loss:  0.10535860061645508
0  loss:  0.1556115448474884
0  loss:  0.18250735104084015
0  loss:  0.06551672518253326
0  loss:  0.12973563373088837
0  loss:  0.10216835886240005
0  loss:  0.12523984909057617
0  loss:  0.18845915794372559
0  loss:  0.07844458520412445
0  loss:  0.08844568580389023
0  loss:  0.14257551729679108
0  loss:  0.20550577342510223
0  loss:  0.1402001976966858
0  loss:  0.16149577498435974
0  loss:  0.06412240862846375
0  loss:  0.12463854253292084
0  loss:  0.15825845301151276
0  loss:  0.18539239466190338
0  loss:  0.09855873137712479
0  loss:  0.2626836597919464
0  loss:  0.1320050209760666
0  loss:  0.10411390662193298
0  loss:  0.12440766394138336
0  loss:  0.1439787596464157
0  loss:  0.07924871146678925
0  loss:  0.13653716444969177
0  loss:  0.09064927697181702
0  loss:  0.11861717700958252
0  loss:  0.1952560395002365
0  loss:  0.12652084231376648
0  loss:  0.11918869614601135
0  loss:  0.1090676337480545
0  loss:  0.06909690797328949
0  loss:  0.1471031755208969
0  loss:  0.2653779089450836
0  loss:  0.12840791046619415
0  loss:  0.155502587556839
0  loss:  0.15914005041122437
0  loss:  0.06527049839496613
0  loss:  0.20294369757175446
0  loss:  0.19533862173557281
0  loss:  0.07698623090982437
0  loss:  0.08558043092489243
0  loss:  0.29416316747665405
0  loss:  0.13641735911369324
0  loss:  0.16336387395858765
0  loss:  0.17078925669193268
0  loss:  0.17395265400409698
0  loss:  0.23261530697345734
0  loss:  0.11183679848909378
0  loss:  0.13454900681972504
0  loss:  0.11454401165246964
0  loss:  0.07140116393566132
0  loss:  0.18926316499710083
0  loss:  0.07957741618156433
0  loss:  0.20359674096107483
0  loss:  0.2502356171607971
0  loss:  0.12680937349796295
0  loss:  0.15978769958019257
0  loss:  0.16486050188541412
0  loss:  0.23228679597377777
0  loss:  0.11256565153598785
0  loss:  0.028320306912064552
0  loss:  0.06395968794822693
0  loss:  0.12312755733728409
0  loss:  0.19690410792827606
0  loss:  0.2368256002664566
0  loss:  0.06685550510883331
0  loss:  0.170310378074646
0  loss:  0.19371339678764343
0  loss:  0.13088680803775787
0  loss:  0.09487110376358032
0  loss:  0.2687315046787262
0  loss:  0.09294617176055908
0  loss:  0.18939107656478882
0  loss:  0.22607488930225372
------ 全部罪名 ------
Acc:  0.8121296619031021
mi_f1:  0.6780512305374183
ma_f1:  0.6792242180773806
mi_precision:  0.7516703786191536
mi_recall:  0.6175663311985361
------ 交通肇事 ------
Acc:  0.9010526315789473
mi_f1:  0.852852852852853
ma_f1:  0.8545859847971993
mi_precision:  0.8606060606060606
mi_recall:  0.8452380952380952
------ 抢劫 ------
Acc:  0.7563451776649747
mi_f1:  0.6275862068965518
ma_f1:  0.6228924126856684
mi_precision:  0.7459016393442623
mi_recall:  0.5416666666666666
------ 抢夺 ------
Acc:  0.79
mi_f1:  0.6505190311418685
ma_f1:  0.6640948662551787
mi_precision:  0.6351351351351351
mi_recall:  0.6666666666666666
------ 过失致人死亡 ------
Acc:  0.8148148148148148
mi_f1:  0.7058823529411766
ma_f1:  0.7010006211910079
mi_precision:  0.7883211678832117
mi_recall:  0.6390532544378699
------ 贪污 ------
Acc:  0.7675544794188862
mi_f1:  0.540084388185654
ma_f1:  0.5271026543012471
mi_precision:  0.7032967032967034
mi_recall:  0.4383561643835616
------ 挪用公款 ------
Acc:  0.8266331658291457
mi_f1:  0.6937269372693726
ma_f1:  0.646923899583474
mi_precision:  0.8103448275862069
mi_recall:  0.6064516129032258
------ 挪用资金 ------
Acc:  0.8126520681265207
mi_f1:  0.618867924528302
ma_f1:  0.6097807442762323
mi_precision:  0.6890756302521008
mi_recall:  0.5616438356164384
0   tensor(5.9929, device='cuda:0', grad_fn=<CopyBackwards>)
1   tensor(0., device='cuda:0', grad_fn=<CopyBackwards>)
2   tensor(0., device='cuda:0', grad_fn=<CopyBackwards>)
3   tensor(0., device='cuda:0', grad_fn=<CopyBackwards>)
4   tensor(0., device='cuda:0', grad_fn=<CopyBackwards>)
5   tensor(0., device='cuda:0', grad_fn=<CopyBackwards>)
6   tensor(0., device='cuda:0', grad_fn=<CopyBackwards>)
7   tensor(0., device='cuda:0', grad_fn=<CopyBackwards>)
8   tensor(0., device='cuda:0', grad_fn=<CopyBackwards>)
9   tensor(0., device='cuda:0', grad_fn=<CopyBackwards>)
10   tensor(0., device='cuda:0', grad_fn=<CopyBackwards>)
11   tensor(0., device='cuda:0', grad_fn=<CopyBackwards>)
dataset loaded
linear.weight   torch.Size([768, 768])
linear.bias   torch.Size([768])
Classify_layer.weight   torch.Size([4, 768])
Classify_layer.bias   torch.Size([4])
start training
0  loss:  1.0425509214401245
0  loss:  0.31663841009140015
0  loss:  0.10511069744825363
0  loss:  0.13796737790107727
0  loss:  0.20862114429473877
0  loss:  0.16245901584625244
0  loss:  0.20483969151973724
0  loss:  0.1698053628206253
0  loss:  0.08314485102891922
0  loss:  0.19821783900260925
0  loss:  0.1333133578300476
0  loss:  0.03936060145497322
0  loss:  0.06593497097492218
0  loss:  0.18945352733135223
0  loss:  0.18737398087978363
0  loss:  0.08582793921232224
0  loss:  0.23746219277381897
0  loss:  0.08034851402044296
0  loss:  0.08154480904340744
0  loss:  0.17340940237045288
0  loss:  0.17546674609184265
0  loss:  0.11626573652029037
0  loss:  0.07143575698137283
0  loss:  0.21417199075222015
0  loss:  0.2441807985305786
0  loss:  0.1648150533437729
0  loss:  0.07444459944963455
0  loss:  0.08660801500082016
0  loss:  0.11366377025842667
0  loss:  0.2667563259601593
0  loss:  0.11447423696517944
0  loss:  0.47344210743904114
0  loss:  0.10212315618991852
0  loss:  0.09470877051353455
0  loss:  0.130807563662529
0  loss:  0.1888628900051117
0  loss:  0.20719271898269653
0  loss:  0.04064292833209038
0  loss:  0.19416551291942596
0  loss:  0.1187509223818779
0  loss:  0.08581457287073135
0  loss:  0.06209263205528259
0  loss:  0.08391120284795761
0  loss:  0.13272570073604584
0  loss:  0.11784438043832779
0  loss:  0.13840560615062714
0  loss:  0.04153827577829361
0  loss:  0.21637630462646484
0  loss:  0.09386984258890152
0  loss:  0.018054768443107605
0  loss:  0.17480431497097015
0  loss:  0.12405691295862198
0  loss:  0.12283004075288773
0  loss:  0.11073320358991623
0  loss:  0.2294224053621292
0  loss:  0.05467872694134712
0  loss:  0.16807708144187927
0  loss:  0.07043665647506714
0  loss:  0.18504416942596436
0  loss:  0.15962064266204834
0  loss:  0.19286248087882996
0  loss:  0.11346329748630524
0  loss:  0.11260678619146347
0  loss:  0.05858050286769867
0  loss:  0.1393795907497406
0  loss:  0.09606602042913437
0  loss:  0.11880532652139664
0  loss:  0.25462090969085693
0  loss:  0.1348118931055069
0  loss:  0.19692263007164001
0  loss:  0.10093387216329575
0  loss:  0.2074604630470276
0  loss:  0.11440887302160263
0  loss:  0.25595617294311523
0  loss:  0.07542399317026138
0  loss:  0.09258901327848434
0  loss:  0.15238028764724731
0  loss:  0.2261923849582672
0  loss:  0.1581551879644394
0  loss:  0.1479099988937378
0  loss:  0.1048867478966713
0  loss:  0.1379484236240387
0  loss:  0.1092909574508667
0  loss:  0.2753850519657135
0  loss:  0.2525136172771454
0  loss:  0.14987319707870483
0  loss:  0.14673319458961487
0  loss:  0.05536212772130966
0  loss:  0.14781345427036285
0  loss:  0.0592978298664093
0  loss:  0.14259204268455505
0  loss:  0.1250985711812973
0  loss:  0.0745692178606987
0  loss:  0.14260484278202057
0  loss:  0.08086972683668137
0  loss:  0.22523348033428192
0  loss:  0.157962366938591
0  loss:  0.09793314337730408
0  loss:  0.03878401964902878
0  loss:  0.25500214099884033
------ 全部罪名 ------
Acc:  0.8258670520231214
mi_f1:  0.683105981112277
ma_f1:  0.6763229429013349
mi_precision:  0.7997542997542998
mi_recall:  0.5961538461538461
------ 交通肇事 ------
Acc:  0.9175257731958762
mi_f1:  0.8301886792452831
ma_f1:  0.8336115860626165
mi_precision:  0.873015873015873
mi_recall:  0.7913669064748201
------ 抢劫 ------
Acc:  0.7886363636363637
mi_f1:  0.5734767025089607
ma_f1:  0.5984278218329585
mi_precision:  0.7142857142857143
mi_recall:  0.47904191616766467
------ 抢夺 ------
Acc:  0.8236775818639799
mi_f1:  0.6861313868613139
ma_f1:  0.6599276118429633
mi_precision:  0.7704918032786885
mi_recall:  0.618421052631579
------ 过失致人死亡 ------
Acc:  0.8364928909952607
mi_f1:  0.7108013937282229
ma_f1:  0.6922539005172381
mi_precision:  0.8031496062992126
mi_recall:  0.6375
------ 贪污 ------
Acc:  0.7928176795580111
mi_f1:  0.652014652014652
ma_f1:  0.6404486667332467
mi_precision:  0.8317757009345794
mi_recall:  0.536144578313253
------ 挪用公款 ------
Acc:  0.7745358090185677
mi_f1:  0.6090225563909775
ma_f1:  0.5693158796945613
mi_precision:  0.7431192660550459
mi_recall:  0.5159235668789809
------ 挪用资金 ------
Acc:  0.8481675392670157
mi_f1:  0.7251908396946565
ma_f1:  0.6872915130995365
mi_precision:  0.8558558558558559
mi_recall:  0.6291390728476821
0   tensor(6.1571, device='cuda:0', grad_fn=<CopyBackwards>)
1   tensor(0., device='cuda:0', grad_fn=<CopyBackwards>)
2   tensor(0., device='cuda:0', grad_fn=<CopyBackwards>)
3   tensor(0., device='cuda:0', grad_fn=<CopyBackwards>)
4   tensor(0., device='cuda:0', grad_fn=<CopyBackwards>)
5   tensor(0., device='cuda:0', grad_fn=<CopyBackwards>)
6   tensor(0., device='cuda:0', grad_fn=<CopyBackwards>)
7   tensor(0., device='cuda:0', grad_fn=<CopyBackwards>)
8   tensor(0., device='cuda:0', grad_fn=<CopyBackwards>)
9   tensor(0., device='cuda:0', grad_fn=<CopyBackwards>)
10   tensor(0., device='cuda:0', grad_fn=<CopyBackwards>)
11   tensor(0., device='cuda:0', grad_fn=<CopyBackwards>)
dataset loaded
linear.weight   torch.Size([768, 768])
linear.bias   torch.Size([768])
Classify_layer.weight   torch.Size([4, 768])
Classify_layer.bias   torch.Size([4])
start training
0  loss:  1.0514105558395386
0  loss:  0.2208632528781891
0  loss:  0.11610153317451477
0  loss:  0.1245839074254036
0  loss:  0.15000472962856293
0  loss:  0.0684046745300293
0  loss:  0.11210814863443375
0  loss:  0.07136743515729904
0  loss:  0.1330617368221283
0  loss:  0.12413052469491959
0  loss:  0.17454467713832855
0  loss:  0.18486790359020233
0  loss:  0.0589059442281723
0  loss:  0.21463386714458466
0  loss:  0.17280372977256775
0  loss:  0.2322988361120224
0  loss:  0.21800057590007782
0  loss:  0.12359576672315598
0  loss:  0.06138801947236061
0  loss:  0.18354234099388123
0  loss:  0.06902659684419632
0  loss:  0.23760361969470978
0  loss:  0.19866575300693512
0  loss:  0.2234906703233719
0  loss:  0.10901149362325668
0  loss:  0.0718657597899437
0  loss:  0.07083284109830856
0  loss:  0.07706206291913986
0  loss:  0.09641993790864944
0  loss:  0.1802702695131302
0  loss:  0.18888603150844574
0  loss:  0.053006671369075775
0  loss:  0.06495095789432526
0  loss:  0.18528053164482117
0  loss:  0.16161853075027466
0  loss:  0.06251764297485352
0  loss:  0.12072660028934479
0  loss:  0.09495999664068222
0  loss:  0.10188663750886917
0  loss:  0.07301963865756989
0  loss:  0.14670030772686005
0  loss:  0.133496955037117
0  loss:  0.0754925012588501
0  loss:  0.05468277633190155
0  loss:  0.11358929425477982
0  loss:  0.08608688414096832
0  loss:  0.050507619976997375
0  loss:  0.10719843208789825
0  loss:  0.1534702032804489
0  loss:  0.1638491004705429
0  loss:  0.12722742557525635
0  loss:  0.13526944816112518
0  loss:  0.217923104763031
0  loss:  0.07791043072938919
0  loss:  0.1405067890882492
0  loss:  0.07522207498550415
0  loss:  0.10766075551509857
0  loss:  0.147023007273674
0  loss:  0.037719205021858215
0  loss:  0.144678995013237
0  loss:  0.1277051717042923
0  loss:  0.02376687526702881
0  loss:  0.11659008264541626
0  loss:  0.13993966579437256
0  loss:  0.12407875806093216
0  loss:  0.12423871457576752
0  loss:  0.15057136118412018
0  loss:  0.19678185880184174
0  loss:  0.0575767420232296
0  loss:  0.09428796917200089
0  loss:  0.0376741960644722
0  loss:  0.0717647597193718
0  loss:  0.2059307098388672
0  loss:  0.2478351593017578
0  loss:  0.1608494371175766
0  loss:  0.23627711832523346
0  loss:  0.03776862472295761
0  loss:  0.0504278801381588
0  loss:  0.16368475556373596
0  loss:  0.044964749366045
0  loss:  0.10165335983037949
0  loss:  0.15133197605609894
0  loss:  0.17836473882198334
0  loss:  0.048895761370658875
0  loss:  0.14881178736686707
0  loss:  0.14405681192874908
0  loss:  0.16705626249313354
0  loss:  0.1847473680973053
0  loss:  0.1719253659248352
0  loss:  0.08945610374212265
0  loss:  0.12489885836839676
0  loss:  0.1250031441450119
0  loss:  0.12301061302423477
0  loss:  0.12694959342479706
0  loss:  0.06767528504133224
0  loss:  0.19237960875034332
0  loss:  0.17082735896110535
0  loss:  0.17464332282543182
0  loss:  0.04225044697523117
0  loss:  0.1508496105670929
------ 全部罪名 ------
Acc:  0.7923797223119148
mi_f1:  0.6225104214914312
ma_f1:  0.631503390968502
mi_precision:  0.7610419026047565
mi_recall:  0.5266457680250783
------ 交通肇事 ------
Acc:  0.8806366047745358
mi_f1:  0.8155339805825244
ma_f1:  0.825174926699317
mi_precision:  0.8936170212765957
mi_recall:  0.75
------ 抢劫 ------
Acc:  0.7583148558758315
mi_f1:  0.5802469135802469
ma_f1:  0.566768810972665
mi_precision:  0.7014925373134329
mi_recall:  0.49473684210526314
------ 抢夺 ------
Acc:  0.8189655172413793
mi_f1:  0.5754385964912282
ma_f1:  0.5878637566137566
mi_precision:  0.6666666666666666
mi_recall:  0.5061728395061729
------ 过失致人死亡 ------
Acc:  0.8188405797101449
mi_f1:  0.6896551724137931
ma_f1:  0.6951259721162084
mi_precision:  0.7333333333333333
mi_recall:  0.650887573964497
------ 贪污 ------
Acc:  0.7274509803921568
mi_f1:  0.4533333333333333
ma_f1:  0.4898628702629056
mi_precision:  0.6601941747572816
mi_recall:  0.34517766497461927
------ 挪用公款 ------
Acc:  0.757455268389662
mi_f1:  0.5519287833827893
ma_f1:  0.5258037492254288
mi_precision:  0.768595041322314
mi_recall:  0.4305555555555556
------ 挪用资金 ------
Acc:  0.8174603174603174
mi_f1:  0.6947368421052632
ma_f1:  0.6640473229092632
mi_precision:  0.8918918918918919
mi_recall:  0.5689655172413793
0   tensor(6.0002, device='cuda:0', grad_fn=<CopyBackwards>)
1   tensor(0., device='cuda:0', grad_fn=<CopyBackwards>)
2   tensor(0., device='cuda:0', grad_fn=<CopyBackwards>)
3   tensor(0., device='cuda:0', grad_fn=<CopyBackwards>)
4   tensor(0., device='cuda:0', grad_fn=<CopyBackwards>)
5   tensor(0., device='cuda:0', grad_fn=<CopyBackwards>)
6   tensor(0., device='cuda:0', grad_fn=<CopyBackwards>)
7   tensor(0., device='cuda:0', grad_fn=<CopyBackwards>)
8   tensor(0., device='cuda:0', grad_fn=<CopyBackwards>)
9   tensor(0., device='cuda:0', grad_fn=<CopyBackwards>)
10   tensor(0., device='cuda:0', grad_fn=<CopyBackwards>)
11   tensor(0., device='cuda:0', grad_fn=<CopyBackwards>)
0.653913567234814
